{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D map fitting\n",
    "\n",
    "## Prerequisites:\n",
    " - To understand how a generel modelling and fiiting works in gammapy, please refer to the [analysis_3d tutorial](../3D/analysis_3d.ipynb)\n",
    "\n",
    "## Context:\n",
    "We often want the determine the position and morphology of an object. To do so, we don't necessarily have to resort to a full 3D fitting but can perform a simple image fitting, in particular, in an energy range where the PSF does not vary strongly, or if we want to explore a possible energy dependance of the morphology.\n",
    "\n",
    "\n",
    "## Objective: \n",
    "To localize a source and/or constrain its morphology.\n",
    "\n",
    "## Proposed approach:\n",
    "\n",
    "The first step here, as in most analysis with DL3 data, is to create reduced datasets. For this, we will use the `Analysis` class to create a single set of stacked maps with a single bin in energy (thus, an *image* which behaves as a *cube*). This, we will then model with a spatial model of our choice, while keeping the spectral model fixed to an integrated power law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As usual, we'll start with some general imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import gammapy specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.analysis import Analysis, AnalysisConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a config file for out analysis. You may load this from disc if you have a pre-defined config file.\n",
    "\n",
    "Here, we use 3 simulated CTA runs of the galactic center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AnalysisConfig()\n",
    "# Selecting the observations\n",
    "config.observations.datastore = \"$GAMMAPY_DATA/cta-1dc/index/gps/\"\n",
    "config.observations.obs_ids = [110380, 111140, 111159]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, gammapy implements 2D analysis as a special case of 3D analysis (one one bin in energy). So, we must specify the type of analysis as *3D*, and define the geometry of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.datasets.type = \"3d\"\n",
    "config.datasets.geom.wcs.skydir = {\n",
    "    \"lon\": \"0 deg\",\n",
    "    \"lat\": \"0 deg\",\n",
    "    \"frame\": \"galactic\",\n",
    "}  # The WCS geometry - centered on the galactic center\n",
    "config.datasets.geom.wcs.width = {\"width\": \"8 deg\", \"height\": \"6 deg\"}\n",
    "config.datasets.geom.wcs.binsize = \"0.02 deg\"\n",
    "\n",
    "# The FoV radius to use for cutouts\n",
    "config.datasets.geom.selection.offset_max = 2.5 * u.deg\n",
    "config.datasets.safe_mask.methods = [\"offset-max\"]\n",
    "config.datasets.safe_mask.parameters = {\"offset_max\": 2.5 * u.deg}\n",
    "config.datasets.background.method = \"fov_background\"\n",
    "config.fit.fit_range = {\"min\": \"0.1 TeV\", \"max\": \"30.0 TeV\"}\n",
    "\n",
    "# We now fix the energy axis for the counts map - (the reconstructed energy binning)\n",
    "config.datasets.geom.axes.energy.min = \"0.1 TeV\"\n",
    "config.datasets.geom.axes.energy.max = \"10 TeV\"\n",
    "config.datasets.geom.axes.energy.nbins = 1\n",
    "\n",
    "config.datasets.geom.wcs.binsize_irf = 0.2 * u.deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the config file and create a single `MapDataset` containing `counts`, `background`, `exposure`, `psf` and `edisp` maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis = Analysis(config)\n",
    "analysis.get_observations()\n",
    "analysis.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts and background maps have only one bin in reconstructed energy. The exposure and IRF maps are in true energy, and hence, have a different binning based upon the binning of the IRFs. We need not bother about them presently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a quick look of these maps in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx-thumbnail": {
     "tooltip": "Source modelling and fitting in stacked observations using the high level interface."
    }
   },
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].counts.reduce_over_axes().plot(vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Now, we define a model to be fitted to the dataset. **The important thing to note here is the dummy spectral model - an integrated powerlaw with only free normalisation**. Here, we use its YAML definition to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = \"\"\"\n",
    "components:\n",
    "- name: GC-1\n",
    "  type: SkyModel\n",
    "  spatial:\n",
    "    type: PointSpatialModel\n",
    "    frame: galactic\n",
    "    parameters:\n",
    "    - name: lon_0\n",
    "      value: 0.02\n",
    "      unit: deg\n",
    "    - name: lat_0 \n",
    "      value: 0.01    \n",
    "      unit: deg\n",
    "  spectral:\n",
    "    type: PowerLaw2SpectralModel\n",
    "    parameters:\n",
    "    - name: amplitude      \n",
    "      value: 1.0e-12\n",
    "      unit: cm-2 s-1 \n",
    "    - name: index\n",
    "      value: 2.0\n",
    "      unit: ''\n",
    "      frozen: true\n",
    "    - name: emin\n",
    "      value: 0.1\n",
    "      unit: TeV\n",
    "      frozen: true\n",
    "    - name: emax\n",
    "      value: 10.0\n",
    "      unit: TeV\n",
    "      frozen: true \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.set_models(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will freeze the parameters of the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].background_model.parameters[\"tilt\"].frozen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the fit\n",
    "analysis.run_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the best fit values along with the errors\n",
    "analysis.fit_result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
