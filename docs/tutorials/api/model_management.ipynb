{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "## Aim\n",
    "\n",
    "The main aim of this tutorial is to illustrate model management in Gammapy, specially how to distribute multiple models across multiple datasets. We also show some convenience functions built in gammapy for handling multiple model components.\n",
    "\n",
    "**Note: Since gammapy v0.18, the responsibility of model management is left totally upon the user. All models, including background models, have to be explicitly defined.** To keep track of the used models, we define a global `Models` object (which is a collection of `SkyModel` objects) to which we append and delete models.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Knowledge of 3D analysis, dataset reduction and fitting see [analysis notebook](../starting/analysis_2.ipynb)\n",
    "- Understanding of gammapy models [see the models tutorial](models.ipynb)\n",
    "- Analysis of the [galactic center with Fermi-LAT](../data/fermi_lat.ipynb)\n",
    "- Analysis of the [galactic center with CTA-DC1](../analysis/3D/analysis_3d.ipynb)\n",
    "\n",
    "## Proposed approach\n",
    "\n",
    "To show how datasets interact with models, we use two pre-computed datasets on the galactic center, one from Fermi-LAT and the other from simulated CTA (DC1) data. We demonstrate\n",
    "\n",
    "- Adding background models for each dataset\n",
    "- Sharing a model between multiple datasets\n",
    "\n",
    "We then load models from the Fermi 3FHL catalog to show some convenience handling for multiple `Models` together\n",
    "\n",
    "- accessing models from a catalog\n",
    "- selecting models contributing to a given region\n",
    "- adding and removing models\n",
    "- freezing and thawing multiple model parameters together\n",
    "- serialising models\n",
    "\n",
    "\n",
    "For computational purposes, we do not perform any fitting in this notebook.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.maps import Map\n",
    "from gammapy.datasets import MapDataset, Datasets\n",
    "from gammapy.modeling.models import (\n",
    "    PointSpatialModel,\n",
    "    SkyModel,\n",
    "    TemplateSpatialModel,\n",
    "    PowerLawNormSpectralModel,\n",
    "    Models,\n",
    "    create_fermi_isotropic_diffuse_model,\n",
    "    FoVBackgroundModel,\n",
    ")\n",
    "from regions import CircleSkyRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.modeling.models import GaussianSpatialModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the datasets\n",
    "\n",
    "First, we read some precomputed Fermi and CTA datasets, and create a `Datasets` object containing the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fermi_dataset = MapDataset.read(\n",
    "    \"$GAMMAPY_DATA/fermi-3fhl-gc/fermi-3fhl-gc.fits.gz\", name=\"fermi_dataset\"\n",
    ")\n",
    "cta_dataset = MapDataset.read(\n",
    "    \"$GAMMAPY_DATA/cta-1dc-gc/cta-1dc-gc.fits.gz\", name=\"cta_dataset\"\n",
    ")\n",
    "datasets = Datasets([fermi_dataset, cta_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the counts maps to see the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "ax1 = plt.subplot(121, projection=fermi_dataset.counts.geom.wcs)\n",
    "ax2 = plt.subplot(122, projection=cta_dataset.counts.geom.wcs)\n",
    "\n",
    "\n",
    "datasets[0].counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n",
    "    ax=ax1, stretch=\"sqrt\", add_cbar=True\n",
    ")\n",
    "datasets[1].counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n",
    "    ax=ax2, stretch=\"sqrt\", add_cbar=True\n",
    ")\n",
    "ax1.set_title(\"Fermi counts\")\n",
    "ax2.set_title(\"CTA counts\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.info_table(cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while the datasets have an associated background map, they currently do not have any associated background model. This will be added in the following section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning background models to datasets\n",
    "\n",
    "For any IACT dataset (in this case `cta_dataset`) , we have to create a `FoVBackgroundModel`. Note that `FoVBackgroundModel`\n",
    " must be specified to one dataset only\n",
    "\n",
    "For Fermi-LAT, the background contribution is taken from a diffuse isotropic template. To convert this into a gammapy `SkyModel`, use the helper function `create_fermi_isotropic_diffuse_model()` \n",
    "\n",
    "To attach a model on a particular dataset it is necessary to specify the `datasets_names`. Otherwise, by default, the model will be applied to all the datasets in `datasets` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must create a global `Models` object which acts as the container for all models used in a particular analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Models()  # global models object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FoV background model for CTA data\n",
    "\n",
    "bkg_model = FoVBackgroundModel(dataset_name=cta_dataset.name)\n",
    "models.append(bkg_model)  # Add the bkg_model to models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the fermi isotropic diffuse background model\n",
    "\n",
    "diffuse_iso = create_fermi_isotropic_diffuse_model(\n",
    "    filename=\"$GAMMAPY_DATA/fermi_3fhl/iso_P8R2_SOURCE_V6_v06.txt\",\n",
    ")\n",
    "diffuse_iso.datasets_names = fermi_dataset.name  # specifying the dataset name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(diffuse_iso)  # Add the fermi_bkg_model to models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, add the models to datasets\n",
    "datasets.models = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see that each dataset lists the correct associated models\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a model on multiple datasets \n",
    "\n",
    "In this section, we show how to add a model to multiple datasets. For this,  we specify a list of `datasets_names` to the model. Alternatively, not specifying any `datasets_names` will add it to all the datasets.\n",
    "\n",
    "For this example, we use a template model of the galactic diffuse emission to be shared between the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diffuse model\n",
    "diffuse_galactic_fermi = Map.read(\n",
    "    \"$GAMMAPY_DATA/fermi-3fhl-gc/gll_iem_v06_gc.fits.gz\"\n",
    ")\n",
    "\n",
    "template_diffuse = TemplateSpatialModel(\n",
    "    diffuse_galactic_fermi, normalize=False\n",
    ")  # the template model in this case is already a full 3D model, it should not be normalised\n",
    "\n",
    "diffuse_iem = SkyModel(\n",
    "    spectral_model=PowerLawNormSpectralModel(),\n",
    "    spatial_model=template_diffuse,\n",
    "    name=\"diffuse-iem\",\n",
    "    datasets_names=[\n",
    "        cta_dataset.name,\n",
    "        fermi_dataset.name,\n",
    "    ],  # specifying list of dataset names\n",
    ")  # A power law spectral correction is applied in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, add the diffuse model to the global models list\n",
    "models.append(diffuse_iem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add it to the datasets, and inspect\n",
    "datasets.models = models\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `diffuse-iem` model is correctly present on both. Now, you can proceed with the fit. For computational purposes, we skip it in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# fit2 = Fit(datasets)\n",
    "# result2 = fit2.run()\n",
    "# print(result2.success)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models from a catalog\n",
    "\n",
    "We now load the Fermi 3FHL catalog and demonstrate some convenience functions. For more details on using gammapy catalog, see here[catalogs.ipynb]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.catalog import SourceCatalog3FHL\n",
    "\n",
    "catalog = SourceCatalog3FHL()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first choose some relevant models from the catalog and create a new `Models` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_sep = catalog.positions.separation(\n",
    "    SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\")\n",
    ")\n",
    "models_3fhl = [\n",
    "    _.sky_model() for k, _ in enumerate(catalog) if gc_sep[k].value < 8\n",
    "]\n",
    "models_3fhl = Models(models_3fhl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_3fhl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting models contributing to a given region\n",
    "\n",
    "We now use `Models.select_region()` to get a subset of models contributing to a particular region. You can also use `Models.select_mask()` to get models lying inside the `True` region of a mask map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = CircleSkyRegion(\n",
    "    center=SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\"), radius=3.0 * u.deg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected = models_3fhl.select_region(region)\n",
    "len(models_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to assign `models_3fhl` to the Fermi dataset, and `models_selected` to both the CTA and Fermi datasets. For this, we explicitlty mention the `datasets_names` to the former, and leave it `None` (default) for the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_3fhl:\n",
    "    if model not in models_selected:\n",
    "        model.datasets_names = fermi_dataset.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the models to datasets\n",
    "datasets.models = models_3fhl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the models on a particular dataset, you can simply see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fermi dataset models: \", datasets[0].models.names)\n",
    "print(\"\\n CTA dataset models: \", datasets[1].models.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining two `Models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Models` can be extended simply as as python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.extend(models_selected)\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting models from a list\n",
    "\n",
    "A `Model` can be selected from a list of `Models` by specifying its index or its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_3fhl[0]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively\n",
    "model = models_3fhl[\"3FHL J1731.7-3003\"]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Models.select` can be used to select all models satisfying a list of conditions.\n",
    "To select all models applied on the cta_dataset with the characters `1748` in the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = models_3fhl.select(\n",
    "    datasets_names=cta_dataset.name, name_substring=\"1748\"\n",
    ")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `Models.select()` combines the different conditions with an `AND` operator. If one needs to combine conditions with a `OR` operator, the `Models.selection_mask()` method can generate a boolean array that can be used for selection. For ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_mask = models_3fhl.selection_mask(\n",
    "    name_substring=\"1748\"\n",
    ") | models_3fhl.selection_mask(name_substring=\"1731\")\n",
    "\n",
    "models_OR = models_3fhl[selection_mask]\n",
    "print(models_OR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing a model from a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any addition or removal of a model must happen through the global models object, which must then be re-applied on the dataset(s). Note that operations **cannot** be directly performed on `dataset.models()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cta_dataset.models.remove()\n",
    "# * this is forbidden *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the model '3FHL J1744.5-2609'\n",
    "models_3fhl.remove(\"3FHL J1744.5-2609\")\n",
    "len(models_3fhl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After any operation on models, it must be re-applied on the datasets\n",
    "datasets.models = models_3fhl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the models applied on a dataset, you can simply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.models.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting models on a (counts) map\n",
    "\n",
    "The spatial regions of `Models` can be plotted on a given geom using `Models.plot_regions()`. You can also use `Models.plot_positions()` to plot the centers of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx-thumbnail": {
     "tooltip": "Multiple datasets and models interaction in Gammapy."
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "ax1 = plt.subplot(121, projection=fermi_dataset.counts.geom.wcs)\n",
    "ax2 = plt.subplot(122, projection=cta_dataset.counts.geom.wcs)\n",
    "\n",
    "for ax, dataset in zip([ax1, ax2], datasets):\n",
    "    dataset.counts.sum_over_axes().smooth(0.05 * u.deg).plot(\n",
    "        ax=ax, stretch=\"sqrt\", add_cbar=True, cmap=\"afmhot\"\n",
    "    )\n",
    "    dataset.models.plot_regions(ax=ax, color=\"white\")\n",
    "    ax.set_title(dataset.name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing and unfreezing model parameters\n",
    "\n",
    "For a given model, any parameter can be (un)frozen individually. Additionally, `model.freeze` and `model.unfreeze` can be used to freeze and unfreeze all parameters in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models_3fhl[0]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To freeze a single parameter\n",
    "model.spectral_model.index.frozen = True\n",
    "print(model)  # index is now frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To unfreeze a parameter\n",
    "model.spectral_model.index.frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To freeze all parameters of a model\n",
    "model.freeze()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To unfreeze all parameters (except parameters which must remain frozen)\n",
    "model.unfreeze()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only spectral or spatial or temporal components of a model can also be frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To freeze spatial components\n",
    "model.freeze(\"spatial\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if all the parameters of a model are frozen, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.frozen  # False because spectral components are not frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.spatial_model.frozen  # all spatial components are frozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same operations can be performed on `Models` directly - to perform on a list of models at once, eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected.freeze()  # freeze all parameters of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_selected.unfreeze()  # unfreeze all parameters of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the free parameters in the models\n",
    "models_selected.parameters.free_parameters.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more functionalities which you can explore. In general, using `help()` on any function is a quick and useful way to access the documentation. For ex, `Models.unfreeze_all` will unfreeze all parameters, even those which are fixed by default. To see its usage, you can simply type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(models_selected.unfreeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialising models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Models` can be (independently of `Datasets`) written to/ read from a disk as yaml files. \n",
    "Datasets are always serialised along with their associated models, ie, with yaml and fits files.\n",
    "eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save only the models\n",
    "models_3fhl.write(\"3fhl_models.yaml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save datasets and models\n",
    "datasets.write(filename=\"datasets-gc.yaml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read only models\n",
    "models = Models.read(\"3fhl_models.yaml\")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read datasets with models\n",
    "datasets_read = Datasets.read(\"datasets-gc.yaml\")\n",
    "print(datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
