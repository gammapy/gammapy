{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and fitting 2D images using Gammapy\n",
    "\n",
    "## Prerequisites:\n",
    " - To understand how a generel modelling and fiiting works in gammapy, please refer to the [analysis_3d tutorial](analysis_3d.ipynb)\n",
    "\n",
    "## Context:\n",
    "We often want the determine the position and morphology of an object. To do so, we don't necessarily have to resort to a full 3D fitting but can perform a simple image fitting, in particular, in an energy range where the PSF does not vary strongly, or if we want to explore a possible energy dependance of the morphology.\n",
    "\n",
    "\n",
    "## Objective: \n",
    "To localize a source and/or constrain its morphology.\n",
    "\n",
    "## Proposed approach:\n",
    "\n",
    "The first step here, as in most analysis with DL3 data, is to create reduced datasets. For this, we will use the `Analysis` class to create a single set of stacked maps with a single bin in energy (thus, an *image* which behaves as a *cube*). This, we will then model with a spatial model of our choice, while keeping the spectral model fixed to an integrated power law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As usual, we'll start with some general imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "from regions import CircleSkyRegion\n",
    "from astropy.coordinates import Angle\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import gammapy specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.analysis import Analysis, AnalysisConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a config file for out analysis. You may load this from disc if you have a pre-defined config file.\n",
    "\n",
    "Here, we use 3 simulated CTA runs of the galactic center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AnalysisConfig()\n",
    "# Selecting the observations\n",
    "config.observations.datastore = \"$GAMMAPY_DATA/cta-1dc/index/gps/\"\n",
    "config.observations.obs_ids = [110380, 111140, 111159]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, gammapy implements 2D analysis as a special case of 3D analysis (one one bin in energy). So, we must specify the type of analysis as *3D*, and define the geometry of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.datasets.type = \"3d\"\n",
    "config.datasets.geom.wcs.skydir = {\n",
    "    \"lon\": \"0 deg\",\n",
    "    \"lat\": \"0 deg\",\n",
    "    \"frame\": \"galactic\",\n",
    "}  # The WCS geometry - centered on the galactic center\n",
    "config.datasets.geom.wcs.fov = {\"width\": \"10 deg\", \"height\": \"8 deg\"}\n",
    "config.datasets.geom.wcs.binsize = \"0.02 deg\"\n",
    "\n",
    "# The FoV radius to use for cutouts\n",
    "config.datasets.geom.selection.offset_max = 3.5 * u.deg\n",
    "\n",
    "# We now fix the energy axis for the counts map - (the reconstructed energy binning)\n",
    "config.datasets.geom.axes.energy.min = \"0.1 TeV\"\n",
    "config.datasets.geom.axes.energy.max = \"10 TeV\"\n",
    "config.datasets.geom.axes.energy.nbins = 1\n",
    "\n",
    "config.datasets.geom.wcs.binsize_irf = 0.2 * u.deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the config file and create a single `MapDataset` containing `counts`, `background`, `exposure`, `psf` and `edisp` maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis = Analysis(config)\n",
    "analysis.get_observations()\n",
    "analysis.get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts and background maps have only one bin in reconstructed energy. The exposure and IRF maps are in true energy, and hence, have a different binning based upon the binning of the IRFs. We need not bother about them presently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"].counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"].background_model.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.datasets[\"stacked\"].exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Now, we define a model to be fitted to the dataset. **The important thing to note here is the dummy spectral model - an integrated powerlaw with only free normalisation**. Here, we use its YAML definition to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = \"\"\"\n",
    "components:\n",
    "- name: GC-1\n",
    "  type: SkyModel\n",
    "  spatial:\n",
    "    type: PointSpatialModel\n",
    "    frame: galactic\n",
    "    parameters:\n",
    "    - name: lon_0\n",
    "      value: 0.02\n",
    "      unit: deg\n",
    "    - name: lat_0 \n",
    "      value: 0.01    \n",
    "      unit: deg\n",
    "  spectral:\n",
    "    type: PowerLaw2SpectralModel\n",
    "    parameters:\n",
    "    - name: amplitude      \n",
    "      value: 1.0e-12\n",
    "      unit: cm-2 s-1 \n",
    "    - name: index\n",
    "      value: 2.0\n",
    "      unit: ''\n",
    "      frozen: true\n",
    "    - name: emin\n",
    "      value: 0.1\n",
    "      unit: TeV\n",
    "      frozen: true\n",
    "    - name: emax\n",
    "      value: 10.0\n",
    "      unit: TeV\n",
    "      frozen: true \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.set_models(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will freeze the parameters of the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.datasets[\"stacked\"].background_model.parameters[\"norm\"].frozen = True\n",
    "analysis.datasets[\"stacked\"].background_model.parameters[\"tilt\"].frozen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the fit\n",
    "analysis.run_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the best fit values along with the errors\n",
    "analysis.fit_result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
