{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D analysis\n",
    "\n",
    "This tutorial shows how to run a 3D map-based analysis using three example observations of the Galactic center region with CTA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.extern.pathlib import Path\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.irf import EnergyDispersion\n",
    "from gammapy.maps import WcsGeom, MapAxis, Map\n",
    "from gammapy.cube import MapMaker, PSFKernel, MapFit\n",
    "from gammapy.cube.models import SkyModel\n",
    "from gammapy.spectrum.models import PowerLaw\n",
    "from gammapy.image.models import SkyGaussian, SkyPointSource\n",
    "from regions import CircleSkyRegion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gammapy info --no-envvar --no-dependencies --no-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare modeling input data\n",
    "\n",
    "### Prepare input maps\n",
    "\n",
    "We first use the `DataStore` object to access the CTA observations and retrieve a list of observations by passing the observations IDs to the `.obs_list()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which data to use\n",
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/cta-1dc/index/gps/\")\n",
    "obs_ids = [110380, 111140, 111159]\n",
    "obs_list = data_store.obs_list(obs_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a reference geometry for our analysis, We choose a WCS based gemoetry with a binsize of 0.02 deg and also define an energy axis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_axis = MapAxis.from_edges(\n",
    "    np.logspace(-1., 1., 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0),\n",
    "    binsz=0.02,\n",
    "    width=(10, 8),\n",
    "    coordsys=\"GAL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MapMaker` object is initialized with this reference geometry and a field of view cut of 4 deg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "maker = MapMaker(geom, offset_max=4. * u.deg)\n",
    "maps = maker.run(obs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maps are prepare by calling the `.run()` method and passing the observation list `obs_list`. The `.run()` method returns a Python `dict` containing a `counts`, `background` and `exposure` map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the summed counts image looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = maps['counts'].sum_over_axes()\n",
    "counts.smooth(width=0.1 * u.deg).plot(stretch=\"sqrt\", add_cbar=True, vmax=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the background image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = maps['background'].sum_over_axes()\n",
    "background.smooth(width=0.1 * u.deg).plot(stretch=\"sqrt\", add_cbar=True, vmax=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute an excess image just with  a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excess = Map.from_geom(geom.to_image())\n",
    "excess.data = counts.data - background.data\n",
    "excess.smooth(5).plot(stretch=\"sqrt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare IRFs\n",
    "\n",
    "To estimate the mean PSF across all observations at a given source position `src_pos`, we use the `obs_list.make_mean_psf()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean PSF\n",
    "src_pos = SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\")\n",
    "table_psf = obs_list.make_mean_psf(src_pos)\n",
    "\n",
    "# PSF kernel used for the model convolution\n",
    "psf_kernel = PSFKernel.from_table_psf(\n",
    "    table_psf, geom, max_radius=\"0.3 deg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate the mean energy dispersion across all observations at a given source position `src_pos`, we use the `obs_list.make_mean_edisp()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define energy grid\n",
    "energy = energy_axis.edges * energy_axis.unit\n",
    "\n",
    "# mean edisp\n",
    "edisp = obs_list.make_mean_edisp(\n",
    "    position=src_pos, e_true=energy, e_reco=energy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save maps and IRFs to disk\n",
    "\n",
    "It is common to run the preparation step independent of the likelihood fit, because often the preparation of maps, PSF and energy dispersion is slow if you have a lot of data. We first create a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"analysis_3d\")\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the write the maps and IRFs to disk by calling the dedicated `.write()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write maps\n",
    "maps[\"counts\"].write(str(path / \"counts.fits\"), overwrite=True)\n",
    "maps[\"background\"].write(str(path / \"background.fits\"), overwrite=True)\n",
    "maps[\"exposure\"].write(str(path / \"exposure.fits\"), overwrite=True)\n",
    "\n",
    "# write IRFs\n",
    "psf_kernel.write(str(path / \"psf.fits\"), overwrite=True)\n",
    "edisp.write(str(path / \"edisp.fits\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood fit\n",
    "\n",
    "### Reading maps and IRFs\n",
    "As first step we read in the maps and IRFs that we have saved to disk again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read maps\n",
    "maps = {\n",
    "    \"counts\": Map.read(str(path / \"counts.fits\")),\n",
    "    \"background\": Map.read(str(path / \"background.fits\")),\n",
    "    \"exposure\": Map.read(str(path / \"exposure.fits\")),\n",
    "}\n",
    "\n",
    "# read IRFs\n",
    "psf_kernel = PSFKernel.read(str(path / \"psf.fits\"))\n",
    "edisp = EnergyDispersion.read(str(path / \"edisp.fits\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cut out only part of the maps, so that we the fitting step does not take so long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = {\n",
    "    name: m.cutout(SkyCoord(0, 0, unit=\"deg\", frame=\"galactic\"), 2 * u.deg)\n",
    "    for name, m in maps.items()\n",
    "}\n",
    "cmaps[\"counts\"].sum_over_axes().plot(stretch=\"sqrt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit mask\n",
    "\n",
    "To select a certain spatial region and/or energy range for the fit we can create a fit mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Map.from_geom(cmaps[\"counts\"].geom)\n",
    "\n",
    "region = CircleSkyRegion(center=src_pos, radius=0.6 * u.deg)\n",
    "mask.data = mask.geom.region_mask([region])\n",
    "\n",
    "mask.get_image_by_idx((0,)).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we also exclude the range below 0.3 TeV for the fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = mask.geom.get_coord()\n",
    "mask.data &= coords[\"energy\"] > 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fit\n",
    "\n",
    "No we are ready for the actual likelihood fit. We first define the model as a combination of a point source with a powerlaw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model = SkyPointSource(lon_0=\"0.01 deg\", lat_0=\"0.01 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=2.2, amplitude=\"3e-12 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the `MapFit` object by passing the prepared maps, IRFs as well as the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = MapFit(\n",
    "    model=model,\n",
    "    counts=cmaps[\"counts\"],\n",
    "    exposure=cmaps[\"exposure\"],\n",
    "    background=cmaps[\"background\"],\n",
    "    mask=mask,\n",
    "    psf=psf_kernel,\n",
    "    edisp=edisp,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we run the model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model fit\n",
    "\n",
    "Finally we check the model fit by cmputing a residual image. For this we first get the number of predicted counts from the fit evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred = fit.evaluator.compute_npred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute a residual image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = Map.from_geom(cmaps[\"counts\"].geom)\n",
    "residual.data = cmaps[\"counts\"].data - npred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual.sum_over_axes().smooth(width=0.05 * u.deg).plot(cmap=\"coolwarm\", vmin=-3, vmax=3, add_cbar=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently our model should be improved by adding a component for diffuse Galactic emission and at least one second point\n",
    "source (see exercises at the end of the notebook).\n",
    "\n",
    "We can also plot the best fit spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = result.model.spectral_model\n",
    "energy_range = [0.3, 10] * u.TeV\n",
    "spec.plot(energy_range=energy_range, energy_power=2)\n",
    "ax = spec.plot_error(energy_range=energy_range, energy_power=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Analyse the second source in the field of view: G0.9+0.1\n",
    "* Run the model fit with energy dispersion (pass edisp to MapFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
