{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light curves with Dataset\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial presents a new light curve estimator that works with dataset objects, in particular MapDataset objects. Here we explain how to compute a light curve from 3D data cubes with Gammapy.\n",
    "\n",
    "This new estimator will replace the existing one in future gammapy releases. \n",
    "\n",
    "We will use the four Crab nebula observations from the [H.E.S.S. first public test data release](https://www.mpi-hd.mpg.de/hfm/HESS/pages/dl3-dr1/) and compute per-observation fluxes. The Crab nebula is not known to be variable at TeV energies, so we expect constant brightness within statistical and systematic errors.\n",
    "\n",
    "The main classes we will use are:\n",
    "\n",
    "* [gammapy.time.LightCurve](https://docs.gammapy.org/dev/api/gammapy.time.LightCurve.html)\n",
    "* [gammapy.time.LightCurveEstimatorNew](https://docs.gammapy.org/dev/api/gammapy.time.LightCurveEstimatorNew.html)\n",
    "\n",
    "## Setup\n",
    "\n",
    "As usual, we'll start with some general imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import gammapy specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import ObservationFilter, DataStore\n",
    "from gammapy.spectrum.models import PowerLaw\n",
    "from gammapy.image.models import SkyPointSource\n",
    "from gammapy.cube.models import SkyModel, BackgroundModel\n",
    "from gammapy.cube import PSFKernel, MapMaker, MapDataset\n",
    "from gammapy.maps import WcsGeom, MapAxis\n",
    "from gammapy.irf import make_mean_psf, make_mean_edisp\n",
    "from gammapy.time import LightCurveEstimator3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the data\n",
    "\n",
    "We look for relevant observations in the datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = DataStore.from_file(\n",
    "    \"$GAMMAPY_DATA/hess-dl3-dr1/hess-dl3-dr3-with-background.fits.gz\"\n",
    ")\n",
    "mask = data_store.obs_table[\"TARGET_NAME\"] == \"Crab\"\n",
    "obs_ids = data_store.obs_table[\"OBS_ID\"][mask].data\n",
    "crab_obs = data_store.get_observations(obs_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define time intervals\n",
    "We create a list of time intervals. Here we use one time bin per observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals = [(obs.tstart, obs.tstop) for obs in crab_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the analysis geometry\n",
    "\n",
    "Here we define the geometry used in the analysis. We use the same WCS map structure but we use two different binnings for reco and true energy axes. This allows for a broader coverage of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target definition\n",
    "target_position = SkyCoord(ra=83.63308, dec=22.01450, unit=\"deg\")\n",
    "\n",
    "# Define geoms\n",
    "emin, emax = [0.7, 10] * u.TeV\n",
    "energy_axis = MapAxis.from_bounds(\n",
    "    emin.value, emax.value, 10, unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=target_position,\n",
    "    binsz=0.04,\n",
    "    width=(2, 2),\n",
    "    coordsys=\"CEL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[energy_axis],\n",
    ")\n",
    "\n",
    "etrue_axis = MapAxis.from_bounds(\n",
    "    0.1, 20, 20, unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "\n",
    "geom_true = WcsGeom.create(\n",
    "    skydir=target_position,\n",
    "    binsz=0.04,\n",
    "    width=(2, 2),\n",
    "    coordsys=\"CEL\",\n",
    "    proj=\"CAR\",\n",
    "    axes=[etrue_axis],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the 3D model \n",
    "\n",
    "The light curve is based on a 3D fit of a map dataset in time bins. We therefore need to define the source model to be applied. Here a point source with power law spectrum. We freeze its parameters assuming they were previously extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source model - Use a pointsource + integrated power law model to directly get flux\n",
    "\n",
    "spatial_model = SkyPointSource(\n",
    "    lon_0=target_position.ra, lat_0=target_position.dec, frame=\"icrs\"\n",
    ")\n",
    "\n",
    "spectral_model = PowerLaw(\n",
    "    index=2.6,\n",
    "    amplitude=2.0e-11 * u.Unit(\"1 / (cm2 s TeV)\"),\n",
    "    reference=1 * u.TeV,\n",
    ")\n",
    "spectral_model.parameters[\"index\"].frozen = False\n",
    "\n",
    "sky_model = SkyModel(\n",
    "    spatial_model=spatial_model, spectral_model=spectral_model, name=\"\"\n",
    ")\n",
    "sky_model.parameters[\"lon_0\"].frozen = True\n",
    "sky_model.parameters[\"lat_0\"].frozen = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction: making the MapDatasets\n",
    "\n",
    "The following function is in charge of the MapDataset production. It will later be fully covered in the data reduction chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_kernel and MapMaker for each segment\n",
    "def make_mapdataset(\n",
    "    observations, target_pos, geom, geom_true, offset_max=2 * u.deg\n",
    "):\n",
    "    maker = MapMaker(geom, offset_max, geom_true=geom_true)\n",
    "    maps = maker.run(observations)\n",
    "    table_psf = make_mean_psf(observations, target_pos)\n",
    "\n",
    "    # PSF kernel used for the model convolution\n",
    "    psf_kernel = PSFKernel.from_table_psf(\n",
    "        table_psf, geom_true, max_radius=\"0.3 deg\"\n",
    "    )\n",
    "    edisp = make_mean_edisp(\n",
    "        observations,\n",
    "        target_pos,\n",
    "        e_true=geom_true.axes[0].edges,\n",
    "        e_reco=geom.axes[0].edges,\n",
    "    )\n",
    "    background_model = BackgroundModel(maps[\"background\"])\n",
    "    background_model.parameters[\"norm\"].frozen = False\n",
    "    background_model.parameters[\"tilt\"].frozen = True\n",
    "\n",
    "    dataset = MapDataset(\n",
    "        counts=maps[\"counts\"],\n",
    "        exposure=maps[\"exposure\"],\n",
    "        background_model=background_model,\n",
    "        psf=psf_kernel,\n",
    "        edisp=edisp,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the actual data reduction in time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for time_interval in time_intervals:\n",
    "    # get filtered observation lists in time interval\n",
    "    obs = crab_obs.select_time(time_interval)\n",
    "    # Proceed with further analysis only if there are observations\n",
    "    # in the selected time window\n",
    "    if len(obs) == 0:\n",
    "        log.warning(\n",
    "            \"No observations found in time interval:\"\n",
    "            \"{t_min} - {t_max}\".format(\n",
    "                t_min=time_interval[0], t_max=time_interval[1]\n",
    "            )\n",
    "        )\n",
    "        continue\n",
    "    dataset = make_mapdataset(obs, target_position, geom, geom_true)\n",
    "    dataset.counts.meta[\"t_start\"] = time_interval[0]\n",
    "    dataset.counts.meta[\"t_stop\"] = time_interval[1]\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the datasets we assign them the model to be fitted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    # Copy the source model\n",
    "    model = sky_model.copy()\n",
    "    model.name = \"crab\"\n",
    "    dataset.model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Estimator creation\n",
    "\n",
    "We can now create the light curve estimator by passing it the list of datasets. \n",
    "We can optionally ask for parameters reoptimization during fit, e.g. to fit background normalization in each time bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_maker = LightCurveEstimator3D(datasets, source=\"crab\", reoptimize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the estimator once we pass it the energy interval on which to compute the integral flux of the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lc = lc_maker.run(e_ref=1 * u.TeV, e_min=1.0 * u.TeV, e_max=10.0 * u.TeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LightCurve object contains a table which we can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.table[\"time_min\", \"time_max\", \"flux\", \"flux_err\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally plot the light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc.plot(marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
