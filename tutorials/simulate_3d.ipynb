{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D simulation and fitting\n",
    "\n",
    "This tutorial shows how to do a 3D map-based simulation and fit.\n",
    "\n",
    "For a tutorial on how to do a 3D map analyse of existing data, see the `analysis_3d` tutorial.\n",
    "\n",
    "This can be useful to do a performance / sensitivity study, or to evaluate the capabilities of Gammapy or a given analysis method. Note that is is a binned simulation as is e.g. done also in Sherpa for Chandra, not an event sampling and anbinned analysis as is done e.g. in the Fermi ST or ctools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.maps import WcsGeom, MapAxis, WcsNDMap, Map\n",
    "from gammapy.spectrum.models import PowerLaw\n",
    "from gammapy.image.models import SkyGaussian\n",
    "from gammapy.cube.models import SkyModel, SkyModels, BackgroundModel\n",
    "from gammapy.cube import MapDataset, MapEvaluator, PSFKernel\n",
    "from gammapy.cube import make_map_exposure_true_energy, make_map_background_irf\n",
    "from gammapy.utils.fitting import Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gammapy info --no-envvar --no-dependencies --no-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = (\n",
    "    \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n",
    ")\n",
    "irfs = load_cta_irfs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to simulate the data\n",
    "spatial_model = SkyGaussian(lon_0=\"0.2 deg\", lat_0=\"0.1 deg\", sigma=\"0.3 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=3, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "sky_model = SkyModel(\n",
    "    spatial_model=spatial_model, spectral_model=spectral_model\n",
    ")\n",
    "print(sky_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define map geometry\n",
    "axis = MapAxis.from_edges(\n",
    "    np.logspace(-1.0, 1.0, 10), unit=\"TeV\", name=\"energy\", interp=\"log\"\n",
    ")\n",
    "geom = WcsGeom.create(\n",
    "    skydir=(0, 0), binsz=0.02, width=(5, 4), coordsys=\"GAL\", axes=[axis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some observation parameters\n",
    "# Here we just have a single observation,\n",
    "# we are not simulating many pointings / observations\n",
    "pointing = SkyCoord(1, 0.5, unit=\"deg\", frame=\"galactic\")\n",
    "livetime = 1 * u.hour\n",
    "offset_max = 2 * u.deg\n",
    "offset = Angle(\"2 deg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = make_map_exposure_true_energy(\n",
    "    pointing=pointing, livetime=livetime, aeff=irfs[\"aeff\"], geom=geom\n",
    ")\n",
    "exposure.slice_by_idx({\"energy\": 3}).plot(add_cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = make_map_background_irf(\n",
    "    pointing=pointing, ontime=livetime, bkg=irfs[\"bkg\"], geom=geom\n",
    ")\n",
    "background.slice_by_idx({\"energy\": 3}).plot(add_cbar=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = irfs[\"psf\"].to_energy_dependent_table_psf(theta=offset)\n",
    "psf_kernel = PSFKernel.from_table_psf(psf, geom, max_radius=0.3 * u.deg)\n",
    "psf_kernel.psf_kernel_map.sum_over_axes().plot(stretch=\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = axis.edges * axis.unit\n",
    "edisp = irfs[\"edisp\"].to_energy_dispersion(\n",
    "    offset, e_reco=energy, e_true=energy\n",
    ")\n",
    "edisp.plot_matrix();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to compute `npred`  maps, i.e. \"predicted counts per pixel\" given the model and the observation infos: exposure, background, PSF and EDISP. The class `MapEvaluator` will compute the predicted counts from the `sky_model` and convolve it with the IRFs. Background counts have to be computed separately using the class `BackgroundModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator_src = MapEvaluator(   \n",
    "    model=sky_model,\n",
    "    exposure=exposure,\n",
    "    psf=psf_kernel,\n",
    "    edisp=edisp,\n",
    ")\n",
    "npred_src = evaluator_src.compute_npred()\n",
    "background_model = BackgroundModel(background)\n",
    "npred_bkg = background_model.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred_data = npred_src.data + npred_bkg.data\n",
    "npred_map = WcsNDMap(geom, npred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npred_map.sum_over_axes().plot(add_cbar=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one line is the core of how to simulate data when\n",
    "# using binned simulation / analysis: you Poisson fluctuate\n",
    "# npred to obtain simulated observed counts.\n",
    "# Compute counts as a Poisson fluctuation\n",
    "rng = np.random.RandomState(seed=42)\n",
    "counts = rng.poisson(npred_data)\n",
    "counts_map = WcsNDMap(geom, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_map.sum_over_axes().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit\n",
    "\n",
    "Now let's analyse the simulated data.\n",
    "Here we just fit it again with the same model we had before, but you could do any analysis you like here, e.g. fit a different model, or do a region-based analysis, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sky model to fit the data\n",
    "spatial_model = SkyGaussian(lon_0=\"0 deg\", lat_0=\"0 deg\", sigma=\"1 deg\")\n",
    "spectral_model = PowerLaw(\n",
    "    index=2, amplitude=\"1e-11 cm-2 s-1 TeV-1\", reference=\"1 TeV\"\n",
    ")\n",
    "model = SkyModel(spatial_model=spatial_model, spectral_model=spectral_model)\n",
    "\n",
    "# Impose that specrtal index remains within limits\n",
    "spectral_model.parameters[\"index\"].min = 0.0\n",
    "spectral_model.parameters[\"index\"].max = 10.0\n",
    "\n",
    "print(model)\n",
    "\n",
    "#We do not want to fit the background in this case, so we will freeze the parameters\n",
    "background_model.parameters[\"norm\"].value = 1.0\n",
    "background_model.parameters[\"norm\"].frozen = True\n",
    "background_model.parameters[\"tilt\"].frozen = True\n",
    "\n",
    "print(background_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = MapDataset(\n",
    "    model=model,\n",
    "    counts=counts_map,\n",
    "    exposure=exposure,\n",
    "    background_model=background_model,\n",
    "    psf=psf_kernel,\n",
    ")\n",
    "fit = Fit(dataset)\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sky_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best-fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the errors on the model, we can check the covariance table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.parameters.covariance_to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or, to see the value of and error on an individual parameter, say index:\n",
    "print(dataset.parameters['index'].value, dataset.parameters.error('index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show e.g. how to make a residual image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
